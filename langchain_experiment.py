"""Markdown gradio experiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N8Kgpl3tlggmOTGtsqxR0x--oHW3i91y
"""
# Set the API key - if this key gets committed to a gitrepo then it gets 
# disabled
import os
import textwrap

from langchain.chains.summarize import load_summarize_chain
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import TokenTextSplitter
from pyngrok import ngrok

# Set the API key - if this key gets committed to a gitrepo then it gets 
# disabled
NGROK_AUTH_TOKEN = ""
ngrok.set_auth_token(NGROK_AUTH_TOKEN)
MY_API_KEY = ""
os.environ['OPENAI_API_KEY'] = MY_API_KEY

# loader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")
# docs = loader.load()

# text_splitter = TokenTextSplitter(chunk_size=4000, chunk_overlap=0)
# docs = loader.load_and_split(text_splitter=text_splitter)

# print(f"Number of docs: {len(docs)}")
# print()
# print(textwrap.fill(docs[0].page_content, max_lines=10))

# llm = ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo")
# chain = load_summarize_chain(llm, chain_type="map_reduce")
# output = chain.run(docs)

# print()
# print("ChatGPT output:")
# print(textwrap.fill(output))

# the default port is localhost:5000
os.system("mlflow ui &")

# Terminate open tunnels if exist
ngrok.kill()

# Open an HTTPs tunnel on port 5000 for http://localhost:5000
public_url = ngrok.connect("5000")

# public_url = ngrok.connect(port="5000", proto="http", options={"bind_tls": True})
print("MLflow Tracking UI:", public_url)

